{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detectron2_pose_estimation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Q0SYdjS-t8VR",
        "FOkZce_GrOsw",
        "krvmfrl3rRa0",
        "ZrOwW-dArte9",
        "jV2EuSdJtp3u"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2OTRm2Rk9sD"
      },
      "source": [
        "# Pose Estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXb8toPfwhPV"
      },
      "source": [
        "Implementation of [detectron2](https://github.com/facebookresearch/detectron2). Most of the code was taken from [This Google Colab Notebook](https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5?usp=sharing)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0SYdjS-t8VR"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKmbElBLlD_J"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBQjP3nHlK6p"
      },
      "source": [
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xePvea94lO8a"
      },
      "source": [
        "# install detectron2:\n",
        "!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mqr7SIkDlSqr"
      },
      "source": [
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsEfIjx6uELi"
      },
      "source": [
        "#Setup for single image\n",
        "single_img_path = \"/content/drive/My Drive/Colab Notebooks/single.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUgrI4AkwBAd"
      },
      "source": [
        "#Setup for video\n",
        "video_path = '/content/drive/MyDrive/Colab Notebooks/input.mp4'\n",
        "num_frames = 600\n",
        "multiple_img_directory_path = \"/content/drive/My Drive/Colab Notebooks/frames\"\n",
        "multiple_img_directory_path_outputs = \"/content/drive/My Drive/Colab Notebooks/output_frames\"\n",
        "output_video_path = \"/content/drive/My Drive/Colab Notebooks/output.mp4\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOkZce_GrOsw"
      },
      "source": [
        "## Estimation (Single Image)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2utcRAwgCqLT"
      },
      "source": [
        "if True:\n",
        "\n",
        "  im = cv2.imread(single_img_path)\n",
        "  \n",
        "  cfg = get_cfg()\n",
        "  cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\"))\n",
        "  cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
        "  cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\")\n",
        "\n",
        "  predictor = DefaultPredictor(cfg)\n",
        "  outputs = predictor(im)\n",
        "  outputs[\"instances\"].pred_boxes = torch.empty((1,4))\n",
        "  \n",
        "  v = Visualizer(im[:,:,::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "  v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "  cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krvmfrl3rRa0"
      },
      "source": [
        "## split mp4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5osN-r1PrS8W"
      },
      "source": [
        "import cv2\n",
        "vidcap = cv2.VideoCapture(video_path)\n",
        "success,image = vidcap.read()\n",
        "count = 0\n",
        "while success:\n",
        "  cv2.imwrite(f\"{multiple_img_directory_path}/frame{count}.jpg\", image)     # save frame as JPEG file      \n",
        "  success,image = vidcap.read()\n",
        "  print('Read a new frame: ', success)\n",
        "  count += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrOwW-dArte9"
      },
      "source": [
        "## Estimation (Multiple Images)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qAMhL5Nrst-"
      },
      "source": [
        "for i in range(num_frames):\n",
        "  im = cv2.imread(f\"{multiple_img_directory_path}/frame{i}.jpg\")\n",
        "  cfg = get_cfg()\n",
        "  cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\"))\n",
        "  cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
        "  cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\")\n",
        "\n",
        "  predictor = DefaultPredictor(cfg)\n",
        "  outputs = predictor(im)\n",
        "  outputs[\"instances\"].pred_boxes = torch.empty((1,4)) #replace bounding box with an empty tensor to prevent the Visualizer from drawing the bounding box\n",
        "\n",
        "  v = Visualizer(im[:,:,::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "  v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "  # cv2_imshow(v.get_image()[:, :, ::-1])\n",
        "  cv2.imwrite(f'{multiple_img_directory_path_outputs}/oframe{i}.jpg', v.get_image()[:, :, ::-1])\n",
        "  print(f\"frame {i} finished. {num_frames-i} to go.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jV2EuSdJtp3u"
      },
      "source": [
        "## frames to video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlKqfpC6tr-h",
        "outputId": "f3854cbe-bc5b-4c0a-9d4a-4bf8fe7f8767"
      },
      "source": [
        "import cv2\n",
        "import glob\n",
        "import re\n",
        "\n",
        "img_array = []\n",
        "numbers = re.compile(r'(\\d+)')\n",
        "def numericalSort(value):\n",
        "  parts = numbers.split(value)\n",
        "  parts[1::2] = map(int, parts[1::2])\n",
        "  return parts\n",
        "\n",
        "for filename in sorted(glob.glob(f'{multiple_img_directory_path_outputs}/*.jpg') , key=numericalSort):\n",
        "  # print(\"read\")\n",
        "  img = cv2.imread(filename)\n",
        "  height, width, layers = img.shape\n",
        "  size = (width,height)\n",
        "  img_array.append(img)\n",
        "\n",
        "out = cv2.VideoWriter(output_video_path,cv2.VideoWriter_fourcc(*\"DIVX\"), 30, size)\n",
        "\n",
        "for i in range(len(img_array)):\n",
        "  out.write(img_array[i])\n",
        "out.release()\n",
        "\n",
        "\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}